{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joltml import Experiment, Xgboost, Sklearn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "# Logging is done implicitly\n",
    "dataset = fetch_california_housing(as_frame=True)[\"frame\"]\n",
    "dataset = dataset.dropna()\n",
    "training_set = dataset[:16000]\n",
    "prediction_set = dataset.iloc[16000:,:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "experiment = Experiment(training_set,experiment_id='trial1')\n",
    "experiment.add_models([Xgboost()])\n",
    "experiment.regression(target_names=['MedHouseVal'],splits=0.2)\n",
    "# Write results and default evaluation metrics\n",
    "y = experiment.predict(prediction_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(training_set)\n",
    "y = experiment.add_models([Xgboost()]).regression(target_names=['MedHouseVal'], splits=[0.8,0.2]).predict(prediction_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "experiment = Experiment(training_set)\n",
    "y = experiment.add_models([Sklearn(ElasticNet())]).regression(target_names=['MedHouseVal'],splits=[0.8,0.2]).predict(prediction_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, LinearRegression, Lasso\n",
    "\n",
    "experiment = Experiment(training_set, experiment_id=\"trial1\")\n",
    "y = experiment.add_models([Xgboost(),\n",
    "                           Sklearn(ElasticNet()),\n",
    "                           Sklearn(LinearRegression()),\n",
    "                           Sklearn(Lasso()),\n",
    "                           ]).regression(target_names=['MedHouseVal'],splits=[0.8, 0.2]).predict(prediction_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet,\\\n",
    "LinearRegression, Ridge, RidgeCV, SGDRegressor, Lars, Lasso,\\\n",
    "LassoLars, ARDRegression, HuberRegressor, QuantileRegressor,\\\n",
    "RANSACRegressor, TheilSenRegressor\n",
    "\n",
    "experiment = Experiment(training_set, experiment_id=\"trial1\")\n",
    "y = experiment.add_models([Xgboost(),\n",
    "                           Sklearn(ElasticNet()),\n",
    "                           Sklearn(LinearRegression()),\n",
    "                           Sklearn(Ridge()),\n",
    "                           Sklearn(RidgeCV()),\n",
    "                           Sklearn(SGDRegressor()),\n",
    "                           Sklearn(Lars()),\n",
    "                           Sklearn(Lasso()),\n",
    "                           Sklearn(LassoLars()),\n",
    "                           Sklearn(ARDRegression()),\n",
    "                        #    Sklearn(HuberRegressor()),\n",
    "                           ]).regression(target_names=['MedHouseVal'],splits=[0.8, 0.2]).predict(prediction_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joltml import Experiment, Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "a = 1\n",
    "b = 0.5\n",
    "\n",
    "X = torch.linspace(0,10,1000)\n",
    "y = a * X + b\n",
    "\n",
    "data = pd.DataFrame(zip(X,y),columns=['X','y'])\n",
    "training_set = data.iloc[:800]\n",
    "prediction_set = data.iloc[800:,:-1]\n",
    "\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = nn.Parameter(torch.randn(\n",
    "            1, dtype=torch.float), requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.randn(\n",
    "            1, dtype=torch.float), requires_grad=True)\n",
    "\n",
    "    # <- \"x\" is the input data (e.g. training/testing features)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.a*x + self.b\n",
    "\n",
    "\n",
    "experiment = Experiment(training_set)\n",
    "y = experiment.add_models([Pytorch(RegressionModel())]).regression(\n",
    "    target_names=['y'], splits=[0.8, 0.2]).predict(prediction_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joltml import Experiment, Pytorch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "# Logging is done implicitly\n",
    "dataset = fetch_california_housing(as_frame=True)[\"frame\"]\n",
    "dataset = dataset.dropna()\n",
    "dataset.astype(np.float32)\n",
    "dataset = dataset.sample(frac=1)\n",
    "training_size = int(0.9*len(dataset))\n",
    "training_set = dataset[:training_size]\n",
    "prediction_set = dataset.iloc[training_size:,:-1]\n",
    "prediction_y = dataset.iloc[training_size:,-1]\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(training_set.shape[1]-1, 24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")\n",
    "\n",
    "experiment = Experiment(training_set)\n",
    "y = experiment.add_models([Pytorch(model)]).regression(\n",
    "    target_names=['MedHouseVal'], splits=[0.8, 0.2]).predict(prediction_set)\n",
    "from joltml.joltmeter import RegressionMetrics\n",
    "print(RegressionMetrics.mean_absolute_error.evaluate(y[0].detach().numpy(),prediction_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "# Logging is done implicitly\n",
    "# https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset\n",
    "dataset = load_diabetes(as_frame=True)[\"frame\"]\n",
    "dataset = dataset.dropna()\n",
    "training_set = dataset[:350]\n",
    "prediction_set = dataset.iloc[350:,:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(training_set,experiment_id='diabetes_1')\n",
    "experiment.add_models([Xgboost(n_estimators=400)])\n",
    "experiment.regression(target_names=['target'],splits=0.2)\n",
    "# Write results and default evaluation metrics\n",
    "y = experiment.predict(prediction_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "# Logging is done implicitly\n",
    "# https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset\n",
    "dataset = load_iris(as_frame=True)[\"frame\"]\n",
    "dataset = dataset.dropna()\n",
    "training_set = dataset[:100]\n",
    "prediction_set = dataset.iloc[100:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: []\n",
      "[0]\tvalidation_0-logloss:0.46296\n",
      "[1]\tvalidation_0-logloss:0.32417\n",
      "[2]\tvalidation_0-logloss:0.23498\n",
      "[3]\tvalidation_0-logloss:0.17444\n",
      "[4]\tvalidation_0-logloss:0.13199\n",
      "[5]\tvalidation_0-logloss:0.10156\n",
      "[6]\tvalidation_0-logloss:0.07940\n",
      "[7]\tvalidation_0-logloss:0.06304\n",
      "[8]\tvalidation_0-logloss:0.05082\n",
      "[9]\tvalidation_0-logloss:0.04158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-logloss:0.03452\n",
      "[11]\tvalidation_0-logloss:0.02905\n",
      "[12]\tvalidation_0-logloss:0.02476\n",
      "[13]\tvalidation_0-logloss:0.02477\n",
      "[14]\tvalidation_0-logloss:0.02477\n",
      "[15]\tvalidation_0-logloss:0.02477\n",
      "[16]\tvalidation_0-logloss:0.02477\n",
      "[17]\tvalidation_0-logloss:0.02477\n",
      "[18]\tvalidation_0-logloss:0.02477\n",
      "[19]\tvalidation_0-logloss:0.02477\n",
      "[20]\tvalidation_0-logloss:0.02477\n",
      "[21]\tvalidation_0-logloss:0.02477\n",
      "[22]\tvalidation_0-logloss:0.02477\n",
      "[23]\tvalidation_0-logloss:0.02477\n",
      "[24]\tvalidation_0-logloss:0.02477\n",
      "[25]\tvalidation_0-logloss:0.02477\n",
      "[26]\tvalidation_0-logloss:0.02477\n",
      "[27]\tvalidation_0-logloss:0.02477\n",
      "[28]\tvalidation_0-logloss:0.02477\n",
      "[29]\tvalidation_0-logloss:0.02477\n",
      "[30]\tvalidation_0-logloss:0.02477\n",
      "[31]\tvalidation_0-logloss:0.02477\n",
      "[32]\tvalidation_0-logloss:0.02477\n",
      "[33]\tvalidation_0-logloss:0.02477\n",
      "[34]\tvalidation_0-logloss:0.02477\n",
      "[35]\tvalidation_0-logloss:0.02477\n",
      "[36]\tvalidation_0-logloss:0.02477\n",
      "[37]\tvalidation_0-logloss:0.02477\n",
      "[38]\tvalidation_0-logloss:0.02477\n",
      "[39]\tvalidation_0-logloss:0.02477\n",
      "[40]\tvalidation_0-logloss:0.02477\n",
      "[41]\tvalidation_0-logloss:0.02477\n",
      "[42]\tvalidation_0-logloss:0.02477\n",
      "[43]\tvalidation_0-logloss:0.02477\n",
      "[44]\tvalidation_0-logloss:0.02477\n",
      "[45]\tvalidation_0-logloss:0.02477\n",
      "[46]\tvalidation_0-logloss:0.02477\n",
      "[47]\tvalidation_0-logloss:0.02477\n",
      "[48]\tvalidation_0-logloss:0.02477\n",
      "[49]\tvalidation_0-logloss:0.02477\n",
      "[50]\tvalidation_0-logloss:0.02477\n",
      "[51]\tvalidation_0-logloss:0.02477\n",
      "[52]\tvalidation_0-logloss:0.02477\n",
      "[53]\tvalidation_0-logloss:0.02477\n",
      "[54]\tvalidation_0-logloss:0.02477\n",
      "[55]\tvalidation_0-logloss:0.02477\n",
      "[56]\tvalidation_0-logloss:0.02477\n",
      "[57]\tvalidation_0-logloss:0.02477\n",
      "[58]\tvalidation_0-logloss:0.02477\n",
      "[59]\tvalidation_0-logloss:0.02477\n",
      "[60]\tvalidation_0-logloss:0.02477\n",
      "[61]\tvalidation_0-logloss:0.02477\n",
      "[62]\tvalidation_0-logloss:0.02477\n",
      "[63]\tvalidation_0-logloss:0.02477\n",
      "[64]\tvalidation_0-logloss:0.02477\n",
      "[65]\tvalidation_0-logloss:0.02477\n",
      "[66]\tvalidation_0-logloss:0.02477\n",
      "[67]\tvalidation_0-logloss:0.02477\n",
      "[68]\tvalidation_0-logloss:0.02477\n",
      "[69]\tvalidation_0-logloss:0.02477\n",
      "[70]\tvalidation_0-logloss:0.02477\n",
      "[71]\tvalidation_0-logloss:0.02477\n",
      "[72]\tvalidation_0-logloss:0.02477\n",
      "[73]\tvalidation_0-logloss:0.02477\n",
      "[74]\tvalidation_0-logloss:0.02477\n",
      "[75]\tvalidation_0-logloss:0.02477\n",
      "[76]\tvalidation_0-logloss:0.02477\n",
      "[77]\tvalidation_0-logloss:0.02477\n",
      "[78]\tvalidation_0-logloss:0.02477\n",
      "[79]\tvalidation_0-logloss:0.02477\n",
      "[80]\tvalidation_0-logloss:0.02477\n",
      "[81]\tvalidation_0-logloss:0.02477\n",
      "[82]\tvalidation_0-logloss:0.02477\n",
      "[83]\tvalidation_0-logloss:0.02477\n",
      "[84]\tvalidation_0-logloss:0.02477\n",
      "[85]\tvalidation_0-logloss:0.02477\n",
      "[86]\tvalidation_0-logloss:0.02477\n",
      "[87]\tvalidation_0-logloss:0.02477\n",
      "[88]\tvalidation_0-logloss:0.02477\n",
      "[89]\tvalidation_0-logloss:0.02477\n",
      "[90]\tvalidation_0-logloss:0.02477\n",
      "[91]\tvalidation_0-logloss:0.02477\n",
      "[92]\tvalidation_0-logloss:0.02477\n",
      "[93]\tvalidation_0-logloss:0.02477\n",
      "[94]\tvalidation_0-logloss:0.02477\n",
      "[95]\tvalidation_0-logloss:0.02477\n",
      "[96]\tvalidation_0-logloss:0.02477\n",
      "[97]\tvalidation_0-logloss:0.02477\n",
      "[98]\tvalidation_0-logloss:0.02477\n",
      "[99]\tvalidation_0-logloss:0.02477\n",
      "Saving model 2b84c29b-4d28-45e3-985e-30cd1390bbb4 in .//jolt_lab/iris_1/e680bd63-ab37-41be-b743-8071f80d4919/models/2b84c29b-4d28-45e3-985e-30cd1390bbb4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\MyCodes\\joltml\\.venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\MyCodes\\joltml\\.venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\MyCodes\\joltml\\.venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\MyCodes\\joltml\\.venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\MyCodes\\joltml\\.venv\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "c:\\MyCodes\\joltml\\.venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\MyCodes\\joltml\\.venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\MyCodes\\joltml\\.venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\MyCodes\\joltml\\.venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\MyCodes\\joltml\\.venv\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "c:\\MyCodes\\joltml\\.venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\MyCodes\\joltml\\.venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\MyCodes\\joltml\\.venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\MyCodes\\joltml\\.venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<joltml.experiment.Experiment at 0x259765ce3d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joltml import Experiment, Xgboost, Sklearn\n",
    "experiment = Experiment(training_set,experiment_id='iris_1')\n",
    "experiment.add_models([Xgboost()])\n",
    "experiment.classification(target_names=['target'],splits=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'booster': {'type': 'categorical', 'values': ['gbtree', 'gblinear', 'dart']},\n",
    "    'lambda': {'type': 'float', 'minimum': 1e-8, 'maximum': 1.0},\n",
    "    'alpha': {'type': 'float', 'minimum': 1e-8, 'maximum': 1.0},\n",
    "}\n",
    "\n",
    "experiment = Experiment(training_set, experiment_id='trial1')\n",
    "experiment.add_models([Xgboost()])\n",
    "experiment.regression_optimize(\n",
    "    targets=['MedHouseVal'], splits=0.2, n_trials=10, params=params)\n",
    "# Write results and default evaluation metrics\n",
    "y = experiment.predict(prediction_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
